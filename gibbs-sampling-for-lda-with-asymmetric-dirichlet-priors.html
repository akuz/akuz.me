<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  ðŸŽ² Gibbs Sampling for LDA with Asymmetric Dirichlet Priors | akuz.me/nko
</title>
  <link rel="canonical" href="/gibbs-sampling-for-lda-with-asymmetric-dirichlet-priors.html">


  <link rel="stylesheet" href="/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="/theme/css/theme.css">

  
  <meta name="description" content="The original articles on LDA (Latent Dirichlet Allocation) assume symmetric Dirichlet priors on topic-words and document-topics distributions. This means that a-priori we assume that all topics are equally likely to appear within each document, and all words are equally likely to appear within each topic. However, if we want to â€¦">



  
</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="/">akuz.me/nko</a></h1>
      <ul class="list-inline">
          <li class="list-inline-item"><a href="/">Home</a></li>
              <li class="list-inline-item text-muted">|</li>
            <li class="list-inline-item"><a href="/nko/">About</a></li>
            <li class="list-inline-item"><a href="/pages/papers.html">Papers</a></li>
            <li class="list-inline-item"><a href="/pages/software.html">Software</a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>  ðŸŽ² Gibbs Sampling for LDA with Asymmetric Dirichlet Priors
</h1>
      <hr>
  <article class="article">
    <header>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2011-07-01T00:00:00+01:00">
          <i class="fa fa-clock-o"></i>
          Fri 01 July 2011
        </li>
        <li class="list-inline-item">
          <i class="fa fa-folder-open-o"></i>
          <a href="/category/papers.html">Papers</a>
        </li>
          <li class="list-inline-item">
            <i class="fa fa-user-o"></i>
              <a href="/author/akuz.html">akuz</a>          </li>
      </ul>
    </header>
    <div class="content">
      <p>The original articles on LDA (Latent Dirichlet Allocation) assume symmetric Dirichlet priors on topic-words and document-topics distributions. This means that a-priori we assume that all topics are equally likely to appear within each document, and all words are equally likely to appear within each topic.</p>
<p>However, if we want to pre-configure the topics, before seeing any data, to have some higher priority words or be more likely to appear within each document (more common topics), then one of the approaches would be to specify the asymmetric Dirichlet priors.</p>
<p>I discuss one of the approaches of how to do it in a reasonable way in the later posts. Bus for now, we need to understand if the same Gibbs sampling formulae apply for the model with asymmetric priors?</p>
<p>For this purpose, Iâ€™ve repeated the derivation of the Gibbs sampling formulae for the case of the asymmetric priors in LDA. The paper can be found <a href="/pdfs/akuz_lda_asym.pdf">here</a> (PDF).</p>
    </div>
  </article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
      <li class="list-inline-item"><a href="/authors.html">Authors</a></li>
    <li class="list-inline-item"><a href="/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="/categories.html">Categories</a></li>
  </ul>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>
</body>

</html>